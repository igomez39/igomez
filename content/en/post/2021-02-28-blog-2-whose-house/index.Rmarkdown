---
title: 'Blog 2: WHO?'
author: "Isabel Gomez"
date: '2021-02-28'
slug: blog-2-whose-house
categories:
- sds-capstone
- ethics
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2021-02-28T01:55:00-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
draft: true 
---

The first chapter in *Data Feminism*  explores the role of power in data science specifically through the lens of the *matrix domination* and by asking the question "who benefits from data science and who is overlooked?"[^1] The answers to these questions can begin to acknowledge the underrepresented communities in data science. Once an underrepresented group is identified the next course for many data scientists is to gather data from that group in order to remedy the bias in their analysis. However, before taking this next step I believe it is important to think of the implications of the data collection and if it is in the best interest of the group from whom we are collecting from.

The authors discuss the CloudWalk company -- a company that recognized they did not have data on Black people and then looked for this data to ensure their AI system was not biased. This appears to be a great move, especially since previous AI systems from other companies  have historically not had enough data to recognize Black people. However one ethical question that needs to be discussed before collecting this data is what are the implications of these AI tools on the citizens they are getting data from? CloudWalk partnered with the Zimbabwean government to provide the data they were looking for. In return, the Zimbabwean government would receive a facial database and surveillance in public transportation zones. The implications this has on the people in the dataset is a huge concern, especially because as the authors point out, Zimbabwe has "a dismal record on human rights."[^2] For this reason, I believe it is necessary for the data analyzers and collectors, in this case CloudWalk, to consider the impact the research will have on the people whose personal data has been collected. It may be that having a diverse range of data may help make the data input less bias, however *how* the data is used could also lead to biases with destructive consequences for individuals. 


There is currently no standardized ethical code to uphold ourselves to as data scientist, however I believe one is necessary as data science work has a real and long-lasting impact on individual lives. The National Academies of Science, Engineering and Medicine proposed a oath similar to that of the Hippocratic Oath taken by doctors. A portion of the Data Science Oath that really fits in the case of CloudWalk is the acknowledgment that data scientists have the power to do harm "and this responsibility must be faced with humbleness and awareness of [the data scientists'] own limitations."[^3] 



[^1]:  1. The Power Chapter. (2020). In Data Feminism. Retrieved from https://undefined.pubpub.org/pub/vi8obxh7

[^2]:  1. The Power Chapter. (2020). In Data Feminism. Retrieved from https://undefined.pubpub.org/pub/vi8obxh7

[^3]: "Appendix D: Data Science Oath." National Academies of Sciences, Engineering, and Medicine. 2018. Data Science for Undergraduates: Opportunities and Options. Washington, DC: The National Academies Press. doi: 10.17226/25104.
